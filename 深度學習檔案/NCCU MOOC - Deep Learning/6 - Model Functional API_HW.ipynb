{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "這次的作業是這樣的，希望你能利用本週教的keras functional API，\n",
    "\n",
    "設計一個mnist的分類模型，這個模型可以一次訓練十個獨立的全連接層，\n",
    "\n",
    "每一個獨立的全連接層的目標是學習答案的十維向量裡的其中一個element，\n",
    "\n",
    "每個全連接層有十個神經元，且都跟隨一個average layer把它的輸出做平均，\n",
    "\n",
    "最後再把這十個層的輸出連接起來，取softmax之後比較結果。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "env: KERAS_BACKEND=tensorflow\n"
     ]
    }
   ],
   "source": [
    "%env KERAS_BACKEND=tensorflow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "#keras \n",
    "import keras\n",
    "import keras.backend as K\n",
    "from keras.models import Model\n",
    "from keras.layers import Dense, Activation, Flatten, Permute, Conv1D, Conv2D, Add, Conv2DTranspose \n",
    "from keras.optimizers import Adam\n",
    "from keras.layers import Input, Dense, concatenate, Lambda, Conv2D, Reshape, BatchNormalization, Lambda, Activation \n",
    "from keras.callbacks import ModelCheckpoint\n",
    "from keras.regularizers import l2\n",
    "from keras.activations import softmax\n",
    "from keras.datasets import mnist\n",
    "from keras.utils import plot_model\n",
    "\n",
    "# tensorflow\n",
    "import tensorflow as tf\n",
    "\n",
    "#numpy\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "x_train shape: (60000, 28, 28)\n",
      "60000 train samples\n",
      "10000 test samples\n"
     ]
    }
   ],
   "source": [
    "# 把mnist load 進來\n",
    "(x_train, y_train), (x_test, y_test) = mnist.load_data()\n",
    "x_train = x_train.astype('float32')\n",
    "x_test = x_test.astype('float32')\n",
    "\n",
    "# 把每個像素的值從(0~255)->(0, 1)\n",
    "x_train /= 255\n",
    "x_test /= 255\n",
    "\n",
    "print('x_train shape:', x_train.shape)\n",
    "print(x_train.shape[0], 'train samples')\n",
    "print(x_test.shape[0], 'test samples')\n",
    "\n",
    "# convert class vectors to binary class matrices\n",
    "y_train = keras.utils.to_categorical(y_train, 10)\n",
    "y_test = keras.utils.to_categorical(y_test, 10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From C:\\Users\\owner\\Anaconda3\\lib\\site-packages\\keras\\backend\\tensorflow_backend.py:74: The name tf.get_default_graph is deprecated. Please use tf.compat.v1.get_default_graph instead.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# 定義一下Average\n",
    "# 喔，keepdims這個參數在這裏真是他X的重要\n",
    "def average_function(inputs):                       # 把運算包成 Layer的方法：def 函數變數(輸入):\n",
    "    return K.mean(inputs, axis=-1, keepdims=True)   # return 用 keras.backend 的運算結果\n",
    "\n",
    "#把定義好的Average用Lambda封裝起來變成layer\n",
    "average_layer = Lambda(average_function)            # 變數名稱 = Lambda(函數)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From C:\\Users\\owner\\Anaconda3\\lib\\site-packages\\keras\\backend\\tensorflow_backend.py:517: The name tf.placeholder is deprecated. Please use tf.compat.v1.placeholder instead.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Model \n",
    "model_input = Input(shape=(28, 28))  # 輸入層\n",
    "flatten = Flatten()(model_input)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 作業開始"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From C:\\Users\\owner\\Anaconda3\\lib\\site-packages\\keras\\backend\\tensorflow_backend.py:4138: The name tf.random_uniform is deprecated. Please use tf.random.uniform instead.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# 請給我十個分開的Dense層，每個層裡面有十個神經元，且輸入都來自flatten\n",
    "# activation function請用relu\n",
    "\n",
    "f_1 = Dense(10, activation='relu')\n",
    "f_2 = Dense(10, activation='relu')\n",
    "f_3 = Dense(10, activation='relu')\n",
    "f_4 = Dense(10, activation='relu')\n",
    "f_5 = Dense(10, activation='relu')\n",
    "f_6 = Dense(10, activation='relu')\n",
    "f_7 = Dense(10, activation='relu')\n",
    "f_8 = Dense(10, activation='relu')\n",
    "f_9 = Dense(10, activation='relu')\n",
    "f_10 = Dense(10, activation='relu')\n",
    "\n",
    "# 每一個Dense層後面都必須再接一個 average_layer，然後把這十個層整理成一個list\n",
    "# 舉例： \n",
    "# x_1 = Dense(10)\n",
    "# avg_1 = averge_layer(x_1)\n",
    "# list.append(...)\n",
    "# 這不是完整的答案，只是個提示。\n",
    "# 且答案不侷限於上述寫法，有更簡潔明快的做法\n",
    "q1 = f_1(flatten)\n",
    "w1 = f_2(flatten)\n",
    "e1 = f_3(flatten)\n",
    "r1 = f_4(flatten)\n",
    "t1 = f_5(flatten)\n",
    "y1 = f_6(flatten)\n",
    "u1 = f_7(flatten)\n",
    "i1 = f_8(flatten)\n",
    "o1 = f_9(flatten)\n",
    "p1 = f_10(flatten)\n",
    "\n",
    "q=average_layer(q1)\n",
    "w=average_layer(w1)\n",
    "e=average_layer(e1)\n",
    "r=average_layer(r1)\n",
    "t=average_layer(t1)\n",
    "y=average_layer(y1)\n",
    "u=average_layer(u1)\n",
    "i=average_layer(i1)\n",
    "o=average_layer(o1)\n",
    "p=average_layer(p1)\n",
    "\n",
    "\n",
    "# 請把這十個層用學長教過的concatenate層連接起來（基本上就是把上面的average_list放進去並加上其他參數。）\n",
    "concatenate_layer = concatenate([q,w,e,r,t,y,u,i,o,p])\n",
    "\n",
    "# Hint: 這次的作業就只有上面的 pass 跟 None 的部分，\n",
    "# 當然你也可以大方地使用 python 的 list comprehension 功能，\n",
    "# 這樣可以少寫幾行。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 作業結束"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_1 (InputLayer)            (None, 28, 28)       0                                            \n",
      "__________________________________________________________________________________________________\n",
      "flatten_1 (Flatten)             (None, 784)          0           input_1[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "dense_1 (Dense)                 (None, 10)           7850        flatten_1[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "dense_2 (Dense)                 (None, 10)           7850        flatten_1[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "dense_3 (Dense)                 (None, 10)           7850        flatten_1[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "dense_4 (Dense)                 (None, 10)           7850        flatten_1[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "dense_5 (Dense)                 (None, 10)           7850        flatten_1[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "dense_6 (Dense)                 (None, 10)           7850        flatten_1[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "dense_7 (Dense)                 (None, 10)           7850        flatten_1[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "dense_8 (Dense)                 (None, 10)           7850        flatten_1[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "dense_9 (Dense)                 (None, 10)           7850        flatten_1[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "dense_10 (Dense)                (None, 10)           7850        flatten_1[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "lambda_1 (Lambda)               (None, 1)            0           dense_1[0][0]                    \n",
      "                                                                 dense_2[0][0]                    \n",
      "                                                                 dense_3[0][0]                    \n",
      "                                                                 dense_4[0][0]                    \n",
      "                                                                 dense_5[0][0]                    \n",
      "                                                                 dense_6[0][0]                    \n",
      "                                                                 dense_7[0][0]                    \n",
      "                                                                 dense_8[0][0]                    \n",
      "                                                                 dense_9[0][0]                    \n",
      "                                                                 dense_10[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_1 (Concatenate)     (None, 10)           0           lambda_1[0][0]                   \n",
      "                                                                 lambda_1[1][0]                   \n",
      "                                                                 lambda_1[2][0]                   \n",
      "                                                                 lambda_1[3][0]                   \n",
      "                                                                 lambda_1[4][0]                   \n",
      "                                                                 lambda_1[5][0]                   \n",
      "                                                                 lambda_1[6][0]                   \n",
      "                                                                 lambda_1[7][0]                   \n",
      "                                                                 lambda_1[8][0]                   \n",
      "                                                                 lambda_1[9][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "activation_1 (Activation)       (None, 10)           0           concatenate_1[0][0]              \n",
      "==================================================================================================\n",
      "Total params: 78,500\n",
      "Trainable params: 78,500\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "#加一個softmax\n",
    "model_output = Activation(\"softmax\")(concatenate_layer)\n",
    "\n",
    "model = Model(model_input, model_output)\n",
    "\n",
    "\n",
    "# 你的model.summary理論上會長這樣\n",
    "print(model.summary())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From C:\\Users\\owner\\Anaconda3\\lib\\site-packages\\keras\\optimizers.py:790: The name tf.train.Optimizer is deprecated. Please use tf.compat.v1.train.Optimizer instead.\n",
      "\n",
      "WARNING:tensorflow:From C:\\Users\\owner\\Anaconda3\\lib\\site-packages\\keras\\backend\\tensorflow_backend.py:3295: The name tf.log is deprecated. Please use tf.math.log instead.\n",
      "\n",
      "WARNING:tensorflow:From C:\\Users\\owner\\Anaconda3\\lib\\site-packages\\tensorflow_core\\python\\ops\\math_grad.py:1424: where (from tensorflow.python.ops.array_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use tf.where in 2.0, which has the same broadcast rule as np.where\n",
      "WARNING:tensorflow:From C:\\Users\\owner\\Anaconda3\\lib\\site-packages\\keras\\backend\\tensorflow_backend.py:986: The name tf.assign_add is deprecated. Please use tf.compat.v1.assign_add instead.\n",
      "\n",
      "WARNING:tensorflow:From C:\\Users\\owner\\Anaconda3\\lib\\site-packages\\keras\\backend\\tensorflow_backend.py:973: The name tf.assign is deprecated. Please use tf.compat.v1.assign instead.\n",
      "\n",
      "WARNING:tensorflow:From C:\\Users\\owner\\Anaconda3\\lib\\site-packages\\keras\\backend\\tensorflow_backend.py:2741: The name tf.Session is deprecated. Please use tf.compat.v1.Session instead.\n",
      "\n",
      "Train on 60000 samples, validate on 10000 samples\n",
      "Epoch 1/10\n",
      "WARNING:tensorflow:From C:\\Users\\owner\\Anaconda3\\lib\\site-packages\\keras\\backend\\tensorflow_backend.py:174: The name tf.get_default_session is deprecated. Please use tf.compat.v1.get_default_session instead.\n",
      "\n",
      "WARNING:tensorflow:From C:\\Users\\owner\\Anaconda3\\lib\\site-packages\\keras\\backend\\tensorflow_backend.py:181: The name tf.ConfigProto is deprecated. Please use tf.compat.v1.ConfigProto instead.\n",
      "\n",
      "WARNING:tensorflow:From C:\\Users\\owner\\Anaconda3\\lib\\site-packages\\keras\\backend\\tensorflow_backend.py:190: The name tf.global_variables is deprecated. Please use tf.compat.v1.global_variables instead.\n",
      "\n",
      "WARNING:tensorflow:From C:\\Users\\owner\\Anaconda3\\lib\\site-packages\\keras\\backend\\tensorflow_backend.py:199: The name tf.is_variable_initialized is deprecated. Please use tf.compat.v1.is_variable_initialized instead.\n",
      "\n",
      "WARNING:tensorflow:From C:\\Users\\owner\\Anaconda3\\lib\\site-packages\\keras\\backend\\tensorflow_backend.py:206: The name tf.variables_initializer is deprecated. Please use tf.compat.v1.variables_initializer instead.\n",
      "\n",
      "60000/60000 [==============================] - 34s 571us/step - loss: 0.4801 - acc: 0.8826 - val_loss: 0.2944 - val_acc: 0.9200\n",
      "Epoch 2/10\n",
      "60000/60000 [==============================] - 23s 376us/step - loss: 0.2848 - acc: 0.9209 - val_loss: 0.2581 - val_acc: 0.9260\n",
      "Epoch 3/10\n",
      "60000/60000 [==============================] - 31s 517us/step - loss: 0.2550 - acc: 0.9288 - val_loss: 0.2373 - val_acc: 0.9330\n",
      "Epoch 4/10\n",
      "60000/60000 [==============================] - 19s 316us/step - loss: 0.2359 - acc: 0.9337 - val_loss: 0.2271 - val_acc: 0.9336\n",
      "Epoch 5/10\n",
      "60000/60000 [==============================] - 32s 532us/step - loss: 0.2209 - acc: 0.9379 - val_loss: 0.2165 - val_acc: 0.9391\n",
      "Epoch 6/10\n",
      "60000/60000 [==============================] - 27s 458us/step - loss: 0.2085 - acc: 0.9409 - val_loss: 0.2087 - val_acc: 0.9389\n",
      "Epoch 7/10\n",
      "60000/60000 [==============================] - 35s 584us/step - loss: 0.1975 - acc: 0.9442 - val_loss: 0.1985 - val_acc: 0.9414\n",
      "Epoch 8/10\n",
      "60000/60000 [==============================] - 30s 507us/step - loss: 0.1871 - acc: 0.9468 - val_loss: 0.1917 - val_acc: 0.9432\n",
      "Epoch 9/10\n",
      "60000/60000 [==============================] - 35s 589us/step - loss: 0.1776 - acc: 0.9496 - val_loss: 0.1831 - val_acc: 0.9472\n",
      "Epoch 10/10\n",
      "60000/60000 [==============================] - 39s 645us/step - loss: 0.1682 - acc: 0.9523 - val_loss: 0.1753 - val_acc: 0.9487\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x1172e59588>"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# compile & fit\n",
    "model.compile(loss=keras.losses.categorical_crossentropy,\n",
    "              optimizer=\"adam\",\n",
    "              metrics=['accuracy'])\n",
    "\n",
    "model.fit(x_train, y_train,\n",
    "          batch_size=32,\n",
    "          epochs=10,\n",
    "          verbose=1,\n",
    "          validation_data=(x_test, y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor 'concatenate_1/concat:0' shape=(?, 10) dtype=float32>"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "concatenate_layer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
