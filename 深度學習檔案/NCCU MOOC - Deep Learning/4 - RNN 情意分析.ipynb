{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 主題:用RNN做情意分析\n",
    "我們終於要介紹三大神經網路的最後一個, 也就是 RNN。RNN 有不少的變型, 例如 LSTM 和 GRU 等等, 不過我們都通稱叫 RNN。RNN 是一種「有記憶」的神經網路, 非常適合時間序列啦, 或是不定長度的輸入資料。\n",
    "\n",
    "我們來看看怎麼樣用 RNN 做電影評論的「情意分析」, 也就是知道一則評論究竟是「正評」還是「負評」"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. 初始準備\n",
    "基本上和之前是一樣的, 我們就不再說明。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "env: KERAS_BACKEND=tensorflow\n"
     ]
    }
   ],
   "source": [
    "%env KERAS_BACKEND=tensorflow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. 讀入 IMDB 電影數據庫\n",
    "今天我們要評入 IMDB 電影數據庫影評的部份。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.datasets import imdb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "(x_train, y_train), (x_test, y_test) = imdb.load_data(num_words=10000)   # num_words=10000 代表只要最常出現的一萬個字"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "25000"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(x_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "25000"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(x_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2.1 輸入資料部份\n",
    "我們來看一下輸入部份長什麼樣子?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[1,\n",
       " 1230,\n",
       " 3765,\n",
       " 566,\n",
       " 97,\n",
       " 189,\n",
       " 102,\n",
       " 86,\n",
       " 7,\n",
       " 32,\n",
       " 4,\n",
       " 973,\n",
       " 16,\n",
       " 55,\n",
       " 355,\n",
       " 18,\n",
       " 14,\n",
       " 20,\n",
       " 4,\n",
       " 64,\n",
       " 542,\n",
       " 173,\n",
       " 16,\n",
       " 4,\n",
       " 893,\n",
       " 2115,\n",
       " 5376,\n",
       " 250,\n",
       " 39,\n",
       " 8013,\n",
       " 4,\n",
       " 1362,\n",
       " 2,\n",
       " 14,\n",
       " 102,\n",
       " 47,\n",
       " 57,\n",
       " 599,\n",
       " 633,\n",
       " 6,\n",
       " 1317,\n",
       " 2,\n",
       " 8,\n",
       " 6,\n",
       " 189,\n",
       " 20,\n",
       " 57,\n",
       " 206,\n",
       " 57,\n",
       " 116,\n",
       " 5,\n",
       " 57,\n",
       " 836,\n",
       " 82,\n",
       " 6,\n",
       " 1317,\n",
       " 2,\n",
       " 3728,\n",
       " 2,\n",
       " 9,\n",
       " 6,\n",
       " 52,\n",
       " 284,\n",
       " 21,\n",
       " 29,\n",
       " 9,\n",
       " 38,\n",
       " 2245,\n",
       " 5,\n",
       " 1044,\n",
       " 11,\n",
       " 14,\n",
       " 15,\n",
       " 45,\n",
       " 619,\n",
       " 50,\n",
       " 71,\n",
       " 6,\n",
       " 171,\n",
       " 531,\n",
       " 15,\n",
       " 71,\n",
       " 424,\n",
       " 8,\n",
       " 30,\n",
       " 163,\n",
       " 6211,\n",
       " 4,\n",
       " 1629,\n",
       " 189,\n",
       " 212,\n",
       " 102,\n",
       " 5,\n",
       " 57,\n",
       " 31,\n",
       " 1498,\n",
       " 11,\n",
       " 4,\n",
       " 311,\n",
       " 13,\n",
       " 197,\n",
       " 15,\n",
       " 14,\n",
       " 20,\n",
       " 16,\n",
       " 1150,\n",
       " 1479,\n",
       " 5,\n",
       " 13,\n",
       " 161,\n",
       " 990,\n",
       " 692,\n",
       " 5,\n",
       " 1706,\n",
       " 12,\n",
       " 69,\n",
       " 77,\n",
       " 1194,\n",
       " 8,\n",
       " 3245,\n",
       " 2001,\n",
       " 553,\n",
       " 67,\n",
       " 14,\n",
       " 20,\n",
       " 48,\n",
       " 25,\n",
       " 423,\n",
       " 13,\n",
       " 131,\n",
       " 124,\n",
       " 51,\n",
       " 25,\n",
       " 122,\n",
       " 236,\n",
       " 1506,\n",
       " 198,\n",
       " 4,\n",
       " 64,\n",
       " 552,\n",
       " 7,\n",
       " 415,\n",
       " 37,\n",
       " 62,\n",
       " 169,\n",
       " 14,\n",
       " 20,\n",
       " 60,\n",
       " 2602,\n",
       " 629,\n",
       " 5,\n",
       " 615,\n",
       " 14,\n",
       " 9,\n",
       " 8,\n",
       " 25,\n",
       " 1230,\n",
       " 3765,\n",
       " 570,\n",
       " 231,\n",
       " 189,\n",
       " 102,\n",
       " 14,\n",
       " 20,\n",
       " 166,\n",
       " 2039,\n",
       " 168,\n",
       " 40,\n",
       " 2450,\n",
       " 5486,\n",
       " 3298]"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_train[99]   # 頻率最常出現的字為1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "218, 189, 141, 550, 147, 43, 123, 562, 233, 130, "
     ]
    }
   ],
   "source": [
    "for i in range(10):\n",
    "    print(len(x_train[i]), end=', ') # 顯示前10筆影評資料的長度"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2.2 輸出資料部份\n",
    "輸出方面應該很容易想像, 我們來看看前 10 筆。結果自然就是 0 (負評) 或 1 (正評)。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_train[15]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1, 0, 0, 1, 0, 0, 1, 0, 1, 0], dtype=int64)"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_train[:10]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2.3 送入神經網路的輸入處理\n",
    "雖然 RNN 是可以處理不同長度的輸入, 在寫程式時我們還是要\n",
    "\n",
    "* 設輸入文字長度的上限\n",
    "* 把每段文字都弄成一樣長, 太短的後面補上 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.preprocessing import sequence"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 整理sequence的長度 = sequence.pad_sequences(你的sequence,maxlen=sequence的最長長度)\n",
    "\n",
    "x_train = sequence.pad_sequences(x_train, maxlen=100)  # 看到第100個字便要決定是正評或是負評，若不足100個字keras會補 0上去\n",
    "x_test = sequence.pad_sequences(x_test, maxlen=100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(25000, 100)"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_train.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. 打造你的 RNN\n",
    "這裡我們選用 LSTM, 基本上用哪種 RNN 寫法都是差不多的!\n",
    "\n",
    "## 3.1 決定神經網路架構\n",
    "* 先將 10000 維的文字壓到 128 維\n",
    "* 然後用 150 個 LSTM\n",
    "* 最後一個 output, 直接用 sigmoid 送出\n",
    "\n",
    "## 3.2 建構我們的神經網路\n",
    "文字我們用 1-hot 表示是很標準的方式, 不過要注意的是, 因為我們指定要 1 萬個字, 所以每個字是用 1 萬維的向量表示! 這一來很浪費記憶空間, 二來字和字間基本上是沒有關係的。我們可以用某種「合理」的方式, 把字壓到比較小的維度, 這些向量又代表某些意思 (比如說兩個字代表的向量角度小表相關程度大) 等等。\n",
    "\n",
    "這聽來很複雜的事叫 \"word embedding\", 而事實上 Keras 會幫我們做。我們只需告訴 Keras 原來最大的數字是多少(10000), 還有我們打算壓到幾維 (128)。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Embedding   # Embedding 將 10000維的文字壓到 128維\n",
    "from keras.layers import LSTM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From C:\\Users\\owner\\Anaconda3\\lib\\site-packages\\keras\\backend\\tensorflow_backend.py:74: The name tf.get_default_graph is deprecated. Please use tf.compat.v1.get_default_graph instead.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "model = Sequential()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From C:\\Users\\owner\\Anaconda3\\lib\\site-packages\\keras\\backend\\tensorflow_backend.py:517: The name tf.placeholder is deprecated. Please use tf.compat.v1.placeholder instead.\n",
      "\n",
      "WARNING:tensorflow:From C:\\Users\\owner\\Anaconda3\\lib\\site-packages\\keras\\backend\\tensorflow_backend.py:4138: The name tf.random_uniform is deprecated. Please use tf.random.uniform instead.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "model.add(Embedding(10000, 128))   # Embedding層可以把離散或整數的資料變得連續"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.add(LSTM(150))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.add(Dense(1, activation='sigmoid'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3.3 組裝\n",
    "這次我們用 binary_crossentropy 做我們的 loss function, 另外用一個很潮的 Adam 學習法。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "embedding_1 (Embedding)      (None, None, 128)         1280000   \n",
      "_________________________________________________________________\n",
      "lstm_1 (LSTM)                (None, 150)               167400    \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 1)                 151       \n",
      "=================================================================\n",
      "Total params: 1,447,551\n",
      "Trainable params: 1,447,551\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 3*(128+150+1)*150=125550  1為biases ; 3為控制LSTM的3個閘門\n",
    "# (128+150+1)*150=41850\n",
    "# 125550 + 41850=167400"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From C:\\Users\\owner\\Anaconda3\\lib\\site-packages\\keras\\optimizers.py:790: The name tf.train.Optimizer is deprecated. Please use tf.compat.v1.train.Optimizer instead.\n",
      "\n",
      "WARNING:tensorflow:From C:\\Users\\owner\\Anaconda3\\lib\\site-packages\\keras\\backend\\tensorflow_backend.py:3376: The name tf.log is deprecated. Please use tf.math.log instead.\n",
      "\n",
      "WARNING:tensorflow:From C:\\Users\\owner\\Anaconda3\\lib\\site-packages\\tensorflow_core\\python\\ops\\nn_impl.py:183: where (from tensorflow.python.ops.array_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use tf.where in 2.0, which has the same broadcast rule as np.where\n"
     ]
    }
   ],
   "source": [
    "model.compile(loss='binary_crossentropy',   # binary_crossentropy做二元分類常用\n",
    "            optimizer='adam',\n",
    "            metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. 訓練\n",
    "我們用的Embedding中,會被batch_size影響輸出。\n",
    "\n",
    "輸入的shape會是(batch_size,每筆上限),\n",
    "\n",
    "也就是(32,100)輸出是(32,100,128),其中128是我們決定是壓成幾維的向量"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From C:\\Users\\owner\\Anaconda3\\lib\\site-packages\\keras\\backend\\tensorflow_backend.py:986: The name tf.assign_add is deprecated. Please use tf.compat.v1.assign_add instead.\n",
      "\n",
      "WARNING:tensorflow:From C:\\Users\\owner\\Anaconda3\\lib\\site-packages\\keras\\backend\\tensorflow_backend.py:973: The name tf.assign is deprecated. Please use tf.compat.v1.assign instead.\n",
      "\n",
      "WARNING:tensorflow:From C:\\Users\\owner\\Anaconda3\\lib\\site-packages\\keras\\backend\\tensorflow_backend.py:2741: The name tf.Session is deprecated. Please use tf.compat.v1.Session instead.\n",
      "\n",
      "Epoch 1/5\n",
      "WARNING:tensorflow:From C:\\Users\\owner\\Anaconda3\\lib\\site-packages\\keras\\backend\\tensorflow_backend.py:174: The name tf.get_default_session is deprecated. Please use tf.compat.v1.get_default_session instead.\n",
      "\n",
      "WARNING:tensorflow:From C:\\Users\\owner\\Anaconda3\\lib\\site-packages\\keras\\backend\\tensorflow_backend.py:181: The name tf.ConfigProto is deprecated. Please use tf.compat.v1.ConfigProto instead.\n",
      "\n",
      "WARNING:tensorflow:From C:\\Users\\owner\\Anaconda3\\lib\\site-packages\\keras\\backend\\tensorflow_backend.py:190: The name tf.global_variables is deprecated. Please use tf.compat.v1.global_variables instead.\n",
      "\n",
      "WARNING:tensorflow:From C:\\Users\\owner\\Anaconda3\\lib\\site-packages\\keras\\backend\\tensorflow_backend.py:199: The name tf.is_variable_initialized is deprecated. Please use tf.compat.v1.is_variable_initialized instead.\n",
      "\n",
      "WARNING:tensorflow:From C:\\Users\\owner\\Anaconda3\\lib\\site-packages\\keras\\backend\\tensorflow_backend.py:206: The name tf.variables_initializer is deprecated. Please use tf.compat.v1.variables_initializer instead.\n",
      "\n",
      "25000/25000 [==============================] - 274s 11ms/step - loss: 0.4274 - acc: 0.7998\n",
      "Epoch 2/5\n",
      "25000/25000 [==============================] - 338s 14ms/step - loss: 0.2702 - acc: 0.8914\n",
      "Epoch 3/5\n",
      "25000/25000 [==============================] - 323s 13ms/step - loss: 0.1982 - acc: 0.9244\n",
      "Epoch 4/5\n",
      "25000/25000 [==============================] - 918s 37ms/step - loss: 0.1419 - acc: 0.9481\n",
      "Epoch 5/5\n",
      "25000/25000 [==============================] - 680s 27ms/step - loss: 0.1092 - acc: 0.9595\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x1ca3de9948>"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(x_train, y_train,\n",
    "         batch_size=32,\n",
    "         epochs=5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. 檢視結果\n",
    "## 5.1 分數\n",
    "我們照例來看看測試資料的分數。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "25000/25000 [==============================] - 61s 2ms/step\n"
     ]
    }
   ],
   "source": [
    "score = model.evaluate(x_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "測試資料的loss 0.46386356464385986\n",
      "測試資料的正確率 0.82068\n"
     ]
    }
   ],
   "source": [
    "print('測試資料的loss', score[0])\n",
    "print('測試資料的正確率', score[1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5.2 儲存結果\n",
    "這裡有 8 成我們可以正確分辨, 看來還不差, 照例我們把結果存檔。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_json = model.to_json()\n",
    "open('imdb_model_architecture.json', 'w').write(model_json)\n",
    "model.save_weights('imdb_model_weights.h5')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "另一種存的方式"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.save('myrnn.h5')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
